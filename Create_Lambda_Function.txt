# Create the Execution Role

1. Open the 'roles page'  (https://console.aws.amazon.com/iam/home#/roles) in the IAM console.
2. Choose 'Create role'.
3. Create a role with the following properties.
                *Trusted entity - AWS Lambda.
                *Permissions - AWSLambdaExecute.
                *Role name - lambda-s3-role.
The AWSLambdaExecute policy has the permissions that the function needs to manage objects in Amazon S3 and write logs to CloudWatch Logs.


# Create the Function
"""
import boto3
import os
import sys
import uuid
from urllib.parse import unquote_plus
from PIL import Image
import PIL.Image

s3_client = boto3.client('s3')

def resize_image(image_path, resized_path):
    with Image.open(image_path) as image:
        image.thumbnail(tuple(x / 2 for x in image.size))
        image.save(resized_path)

def lambda_handler(event, context):
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = unquote_plus(record['s3']['object']['key'])
        tmpkey = key.replace('/', '')
        download_path = '/tmp/{}{}'.format(uuid.uuid4(), tmpkey)
        upload_path = '/tmp/resized-{}'.format(tmpkey)
        s3_client.download_file(bucket, key, download_path)
        resize_image(download_path, upload_path)
        s3_client.upload_file(upload_path, '{}resized'.format(bucket), key)
"""     
1. Copy the sample code into a file named lambda_function.py.
2. Create a virtual environment.
                    # install virtualenv
                    # sudo apt-get update \
                    # && sudo apt-get install -y software-properties-common curl \
                    # && sudo add-apt-repository ppa:deadsnakes/ppa \
                    # && sudo apt-get update \
                    # && sudo apt-get install -y python3.6 python3.6-venv
                    s3-python$ virtualenv -p /usr/bin/python3 py3env
                    s3-python$ source py3env/bin/activate
3. Install libraries in the virtual environment
                    (py3env) s3-python$ pip install Pillow boto3
4. Create a deployment package with the contents of the installed libraries.
                    (py3env) s3-python$ cd $VIRTUAL_ENV/lib/python3.6/site-packages
                    (py3env) python-s3/v-env/lib/python3.6/site-packages$ zip -r9 ${OLDPWD}/function.zip .
5. Add the handler code to the deployment package and deactivate the virtual environment.
                    (py3env) python-s3/v-env/lib/python3.6/site-packages$  cd ${OLDPWD}
                    (py3env) python-s3$ zip -g function.zip lambda_function.py # put it in './'
                        adding: lambda_function.py (deflated 55%)
                    (py3env) python-s3$ deactivate

# Create the function
Create a Lambda function with the create-function command.
$ aws lambda create-function --function-name 'FunctionName' \
--zip-file fileb://function.zip --handler lambda_function.lambda_handler --runtime python3.6 \
--timeout 10 --memory-size 1024 \
--role arn:aws:iam::243119661293:role/lambda-s3-role \
--region us-east-2

# Test the Lambda Function
Save the following Amazon S3 sample event data in a file and save it as inputFile.txt.
{
  "Records":[
    {
      "eventVersion":"2.0",
      "eventSource":"aws:s3",
      "awsRegion":"us-west-2",
      "eventTime":"1970-01-01T00:00:00.000Z",
      "eventName":"ObjectCreated:Put",
      "userIdentity":{
        "principalId":"AIDAJDPLRKLG7UEXAMPLE"
      },
      "requestParameters":{
        "sourceIPAddress":"127.0.0.1"
      },
      "responseElements":{
        "x-amz-request-id":"C3D13FE58DE4C810",
        "x-amz-id-2":"FMyUVURIY8/IgAtTv8xRjskZQpcIZ9KG4V5Wp6S7S/JRWeUWerMUE5JgHvANOjpD"
      },
      "s3":{
        "s3SchemaVersion":"1.0",
        "configurationId":"testConfigRule",
        "bucket":{
          "name":"sourcebucket",
          "ownerIdentity":{
            "principalId":"A3NL1KOZZKExample"
          },
          "arn":"arn:aws:s3:::sourcebucket"
        },
        "object":{
          "key":"HappyFace.jpg",
          "size":1024,
          "eTag":"d41d8cd98f00b204e9800998ecf8427e",
          "versionId":"096fKKXTRTtl3on89fVO.nfljtsv6qko"
        }
      }
    }
  ]
}

# Configure Amazon S3 to Publish Events
## Add permissions to the function policy
$ aws lambda add-permission --function-name 'FunctionName' --principal s3.amazonaws.com \
--statement-id s3invoke --action "lambda:InvokeFunction" \
--source-arn arn:aws:s3:::'BucketName' \
--source-account 243119661293 \
--region us-east-2

## Verify the function's access policy
$ aws lambda get-policy --function-name 'FunctionName' --region us-east-2

## Configure notifications
1. Open the Amazon S3 console (https://console.aws.amazon.com/s3/home?region=us-east-2)
2. Choose the source bucket.
3. Choose Properties.
4. Under Events, configure a notification with the following settings.
                    *Name - lambda-trigger.
                    *Events – ObjectCreate (All).
                    *Send to – Lambda function.
                    *Lambda – 'FunctionName'.
